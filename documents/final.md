# Introduction

Originally, the domain I intended to work in was guitar tablature of unknown quality, though over the course of the half-semester the project has expanded in domain to guitar tab in general. The nature of guitar tablature is such that it is difficult to tell what it would sound like just by looking at it; unlike standard music notation which encodes pitches, tablature encodes string/fret combinations, which will sound entirely different if the tuning of the instrument is changed.
Therefore, without some sort of tool to play it back, it is difficult to judge the quality of tablature without learning to play it first. If a song is complicated, and some tablature for it is just as complicated but wrong, one can waste a great deal of time trying to learn the song from the tablature before realizing anything sounds wrong, hence my original inspiration.

For clarification's sake, I should explain why the domain has expanded. Tablature does not necessarily have any kind of rhythm notation in it, and indeed much of the tablature on the internet which one might check with a hypothetical tool does not. The user of a tab-checking tool would therefore have to take their best guess at the correct rhythm, and should they guess wrong might thereby conclude that an otherwise good piece of tab was not right at all. However, the user of a
tab-creating tool needs make no such guesses, and it is this expanded domain of both checking tab when feasible _and_ creating new tab that really motivates the need for a DSL.

That a DSL is possible in this domain is, I hope, not something I need to argue very strongly; under the broad definition of DSLs that we have employed in this course, guitar tab itself is already a DSL and would be one even if computers did not exist. To make a computer-based DSL in this domain is really just a matter of computerizing tablature and doing something with it. The important question is rather why a DSL is a good choice and not whether it is a feasible one.
In fact for some use-cases, it is not the right choice, which is why there are already alternative tools in the domain. For the most part, these are GUI-based tablature editors, although there are one or two other DSLs in the domain whose functionality is similar to mine but certainly not identical.

The GUI-based tools are particularly good given tab that already exists or exists in part; features such as their ability to play back tab starting at any point speed up the process of
tweaking small sections of a song at a time. However, inputting completely new tab involves using the mouse quite a bit, as well as not the most efficient use of the keyboard in terms of keystrokes and hand positioning. Creating new tablature, then, is where a DSL can be especially useful, because supposing it is entirely text-based, it requires no use of the mouse. Furthermore a language can be designed so the user's hands need not leave typing position to use it.
Ultimately, I would like my language to be usable as effectively a faster input method for GUI-based tools, and also allow for output in the form of nicely-formatted PDFs as well as MIDI files to give more flexibility (these latter two are more or less already implemented).


# Language design
Users write programs in my language by writing in a text file. Given the domain I am working in, I believe something like an IDE would be an appropriate addition to the project should I keep working on it; I am quite certain many guitarists are not familiar with the use of a terminal. That is about where the similarities to general-purpose languages end, however. My syntax is almost entirely a shorthand for guitar tablature, with a few pieces that specify formatting that isn't exactly
part of the tablature itself. Whereas to create tab using a general-purpose language would likely require a good few library calls, in my syntax the user simply writes the tab out in a particular way.

This is a data interpretation language, in that it takes in the tab (that is, the data) and does something with it. I suppose the data structures in the language are staves, which consist of many notes, chords, tempo changes, and time changes in sequence. The user can only create these (by declaring that they exist), not manipulate them. The order of the notes, chords, and tempo and time changes in a staff is exactly the order in which the user writes them. Once these have all been processed, the behavior of a program can be one of two things depending on which the user requests. This is the closest thing to control flow that this language has. Besides the text file that is the program itself, a program in this language requires no inputs. The possible outputs will be PDF, MIDI, LilyPond, and TuxGuitar-readable files, depending on what the user asks for. The PDF and LilyPond outputs can include just standard notation, just tab, or both. For reference (that is, for those who _don't_ want to look at literally everything I've done for this project), [LilyPond](lilypond.org) is more or less LaTeX for music.

Most errors in this language are syntax errors. All errors will be communicated as compile-time errors typically are--that is, with some kind of text output. Presently, the error messages are not very good, and are probably not useful for anyone other than myself, but they are there and they do at least give some indication of _where_ things went wrong. Aside from syntax errors, the errors that it is possible to make are: putting multiple notes in a chord on the same string
(since guitars just don't work that way) and giving invalid string numbers. Eventually, my language needs to enforce consistency between time signature and note durations (for example, a song in 4/4 time should never have four dotted quarter notes in a row), but it does not do so right now since that is a semantic issue and not as much a matter of language design. Currently there is no tool support for the language, but running a program will most likely be easier for a typical user
with a development environment, as I mentioned above.

There is one DSL that I am aware of in this domain besides LilyPond (which is in any case only sort of in the same domain). This other DSL is called [VexTab](www.vexflow.com/vextab/). Syntactically my language is very similar to VexTab, since I largely based my syntax on it. The functionality is somewhat less similar. VexTab is, so far as I can tell, web-based and allows visual and audio output. My language also allows visual and audio output, but first of all it is not web-based.
Furthermore, because my language outputs through LilyPond, which is compatible with LaTeX, users of my language can include tablature in other documents. My future plans for the language as an input method to GUI-based tools is entirely different than anything VexTab does.

# Example programs
The programs themselves can be found in the `src/examples` directory of the project's code repository. Let's have a look at `simple.tc` first. At the beginning of the first line, we have the keyword "staff". This, as you might expect, corresponds to the staff data structure mentioned above, which in turn corresponds to a musical staff. Every program needs at least one staff or there won't be much of anything in the output. On the same line as the staff keyword, we have a staff-level
option. `notation=true` turns on standard notation output (which is off by default). Other options include `tab` and `tuning`, the first of which turns on/off tablature output (on by default), and the second of which specifies the string tunings for that staff (EADGBe by default).

On the line below, the `notes` keyword opens the environment in which we can enter fret/string combinations. The numbers separated by dashes are all fret numbers. A sequence of these must be followed by a `/` and another number. The number after the `/` is the number of the string these notes are played on (for the non-guitarist's reference, the lowest string on a typical guitar is the sixth string and the highest is the first string). No durations have been specified anywhere, so
these notes are all quarter notes, the default value. I recommend just running the program according to the directions in the readme at this point to see how the program corresponds to the output.

Now let's have a look at `full.tc`. The first line is another option, but this one is at the global level. `pdf=true` is redundant since pdf output is on by default, but it's there to show where global options go. MIDI output is also controlled at the global level, and output to a GUI-based tool will be as well when implemented. `time=4/4` sets the time signature to 4/4. This actually represents a _change_ in time signature, and so does not need to be before every `notes` environment in
a staff. If a song changes to 3/4 partway through, then putting `time=3/4` between the appropriate `notes` environments will make that time signature change appear in the output. `tempo:` is followed by `q=160` here. The number is beats per minute, and the `q` means that a quarter note is one beat. Like `time`, this is a tempo _change_, so it can go between `notes` environments as well. The value of a beat can be `w` `h` `q` `e` `s` `t` or `sx` for whole, half, quarter, eighth,
sixteenth, thirty-second, and sixty-fourth notes, or `hd` `qd` etc. for dotted half, quarter, etc.

These letters are also used for the durations of individual notes. If a fret number is preceded by one of those durations followed by a colon, then that note will have that duration, as will all notes following until the next time a duration is written in. So, the first note in `full.tc` is an eighth note, the next two are sixteenth notes, the fourth is another eighth note, and all
of these are played at the fifth fret on the sixth string. In the third `notes` environment there are some parentheses, which delimit chords. Inside the parentheses go a number of fret/string combinations (however many notes are in the chord). These are not the same as the sequences we've already seen. There can only be one fret number before the slash, and no durations can come before these fret numbers. The duration of the chord as a whole can be specified as if it were a
single note. The second chord demonstrates this.

# Language implementation
I chose to implement this as an external DSL. I feel that the data interpretation model is a natural choice for the domain since notation itself is essentially a list of data, and internal DSLs are not as well suited to that computational model. I chose Python as my host language. I considered both Scala and Python, each of which has good parsing tools, but I'm more familiar with Python and I believe my final product is of higher quality for my choice. I was warned that using Java
or C++ would be an exercise in frustration compared to Scala or Python on account of the parsing tools available, or lack thereof. Because I needed to write exactly none of the backend myself, my choice of language did not actually matter that
much from a design perspective.

The architecture of my language is fairly straightforward. At the front end, there is a parser that takes in a text file such as one of the example programs I talked about in the previous section. The parser directly outputs my intermediate representation, which is in the middle. My intermediate representation currently is only compatible with one of the two back ends I hope to have in the future, LilyPond to be specific.

The parser, as I said, outputs my intermediate representation directly, but it does not, for example, create a note as soon as it has a fret and string to work with. Instead, when a phrase of notes (that is, a bunch of notes and a string number) is parsed, a function is passed up instead of the list of tokens from the phrase. The arguments to this function are a rhythm value and a boolean indicating whether that value should be dotted. Eventually all these functions are called in
sequence. The function from a particular phrase returns a list of note objects from my intermediate representation that correspond to the notes in the phrase, and also returns the duration of the last note in the phrase. Then the next phrase's function is called with the duration returned from the current call. Each staff in my intermediate representation is an object and has a list of all the notes on it; the parser goes through each staff environment, makes a list of notes by
calling all the functions returned by parsing phrases, and creates a staff object with that list of notes. Once a staff object has been created for each staff environment, a song object is created with a list containing all those staff objects. That mostly covers how both my parser and intermediate representation work.

My language interfaces with LilyPond as a backend by "writing" a LilyPond program rather than making any library calls. I've simply made a few template files, and used Python's built-in field replacement functionality to ensure everything is valid syntax.

# Evaluation
My language is very DSL-y. As it is an external DSL that only allows the user to write shorthand for guitar tab, it is quite far removed from a general-purpose language. The middle and front end are working very well. All the features I've added to them do what they're supposed to, there's not much else to say about that. Well, I suppose I'm especially pleased that it's been easy to add features so far, since it seems I've designed things well enough that I don't need to do major
refactors to add features.

Features, however, are what the language still needs quite a bit of. On the language side, some less-common but still important bits of musical notation are missing, such as triplets and mutliple voices on the same staff. On the technical side, I have not added any support for output to GUI-based tools. As for the user's experience, I had wanted the process of running a program to be more automated than it is. Currently, running a program outputs a file of LilyPond code, and to
get a PDF or MIDI file, the user has to compile that code themselves, but ideally the user would only get the LilyPond file if they requested it and otherwise it would be compiled automatically and then discarded.

There were two places I ran into trouble. At the beginning of the project, I spent some time trying to figure out how to get output to GUI-based tools working. Unfortunately, the library I was going to use is really not very well documented, I guess because it is a library component of a larger application. From there I chose to focus on interfacing with LilyPond. I think my focus on LilyPond has affected the design of my intermediate representation (specifically, the hierarchy
is similar to the hierarchy of environments in a LilyPond program). I think that drift in the design has furthermore been away from the design of the aforementioned library, and so I've made it more difficult to work with the library than it was before. I believe it is still possible to incorporate it as I had originally planned, but this increase in difficulty has meant that I wasn't able to do so during the class.

I also briefly ran into some trouble with my parser, on account of my choice in parsing library. The library I originally chose to use only supported output in the form of an AST, which it was necessary to walk essentially manually. I found that this did not match up very well with really either my syntax or my intermediate representation, so I ended up re-implementing my parser so I could output my intermediate representation directly.
